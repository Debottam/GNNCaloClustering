{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4560d7",
   "metadata": {},
   "source": [
    "## Required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9210fe68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import uproot\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from collections import namedtuple, defaultdict\n",
    "#import open3d as o3d\n",
    "import random\n",
    "random.seed(42)\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dd03e",
   "metadata": {},
   "source": [
    "## Required data generated by GNNonCalo_Scaling_DataPreparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "786d7a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_cellFeaturesScaled_neighbor= h5py.File(\"./cellFeaturesScaled_train_500evs.hdf5\", 'r')\n",
    "hf_train_edge_source_BD = h5py.File(\"./train_edge_source_BD_500evs.hdf5\", 'r')\n",
    "hf_train_edge_dest_BD = h5py.File(\"./train_edge_dest_BD_500evs.hdf5\", 'r')\n",
    "hf_train_edge_source_noBD = h5py.File(\"./train_edge_source_noBD_500evs.hdf5\", 'r')\n",
    "hf_train_edge_dest_noBD = h5py.File(\"./train_edge_dest_noBD_500evs.hdf5\", 'r')\n",
    "hf_truth_label_train_neighbor= h5py.File(\"./truth_label_train_500evs.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "493afa29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cellFeaturesScaled = hf_cellFeaturesScaled_neighbor.get(\"cellFeatures_trainS\")[:]\n",
    "train_edge_source_BD = hf_train_edge_source_BD.get(\"train_edge_source_BD\")[:]\n",
    "train_edge_dest_BD = hf_train_edge_dest_BD.get(\"train_edge_dest_BD\")[:]\n",
    "train_edge_source_noBD = hf_train_edge_source_noBD.get(\"train_edge_source_noBD\")[:]\n",
    "train_edge_dest_noBD = hf_train_edge_dest_noBD.get(\"train_edge_dest_noBD\")[:]\n",
    "truth_label_train = hf_truth_label_train_neighbor.get(\"truth_label_train\")[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e06cba73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_cellFeaturesScaled_neighbor.close()\n",
    "hf_train_edge_source_BD.close()\n",
    "hf_train_edge_dest_BD.close()\n",
    "hf_train_edge_source_noBD.close()\n",
    "hf_train_edge_dest_noBD.close()\n",
    "hf_truth_label_train_neighbor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f16af783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 187652, 8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellFeaturesScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ef2619c0-7a38-4ac4-a685-467d90525c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58421445, 0.51289224, 0.16380877, 0.23466876, 0.52418755,\n",
       "       0.26086957, 0.09700815, 0.14570355])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellFeaturesScaled[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85fc1d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(cellFeaturesScaled, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb6ebe83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([187652, 8])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee295ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 60000)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_source_BD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97c155",
   "metadata": {},
   "source": [
    "## Preparing bi directional edges (align source and destination) for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "066d56d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([train_edge_source_BD, train_edge_dest_BD], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "78761a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 500, 60000])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a4873a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index_ch = edge_index.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dc56578f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 2, 60000])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_ch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a57de",
   "metadata": {},
   "source": [
    "## Preparing uni directional edges for final binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ebc7400e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index_out = torch.tensor([train_edge_source_noBD, train_edge_dest_noBD], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c1af4ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 500, 30000])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "170ae2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index_out_ch = edge_index_out.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "70149253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 2, 30000])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_out_ch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9360902",
   "metadata": {},
   "source": [
    "## Preparing label (true/Fake) tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e031179d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth_label_train = np.expand_dims(truth_label_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3740e08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1, 30000)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "66454347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(truth_label_train, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c04658ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1, 30000])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29e70f",
   "metadata": {},
   "source": [
    "## Data customization specific to pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e5d4321e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate data_list\n",
    "data_list = []\n",
    "for i in range(500):\n",
    "    x_mat = x[i]\n",
    "    edge_index = edge_index_ch[i]\n",
    "    edge_index, _ = add_self_loops(edge_index)\n",
    "    data = Data(x=x_mat, edge_index=edge_index, edge_index_out = edge_index_out_ch[i], y=y_train[i])\n",
    "    data = ToUndirected()(data)\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b7da986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind0 = data_list[0].edge_index\n",
    "ind1 = data_list[1].edge_index\n",
    "ind2 = data_list[2].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ed6c3de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 247649])\n",
      "torch.Size([2, 247651])\n",
      "torch.Size([2, 247648])\n"
     ]
    }
   ],
   "source": [
    "print(ind0.shape)\n",
    "print(ind1.shape)\n",
    "print(ind2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "26374bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4f1b4ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(data_list):\n",
    "    batch_x = [data.x for data in data_list]\n",
    "    batch_edge_index = [data.edge_index for data in data_list]\n",
    "    batch_edge_index_out = [data.edge_index_out for data in data_list]\n",
    "    batch_y = [data.y for data in data_list]\n",
    "\n",
    "    return batch_x, batch_edge_index, batch_edge_index_out, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0739a74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "24cf7def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "data_loader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d611904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_edge_index, batch_edge_index_out, _ in data_loader:\n",
    "    print(len(batch_edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b4df7d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "204b1c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 247650])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4846a2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30000])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f9dcb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187652"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c19027",
   "metadata": {},
   "source": [
    "## Edge Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a9bcb4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the GNN model for edge classification\n",
    "class EdgeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(EdgeClassifier, self).__init__()\n",
    "\n",
    "        # Node embedding layer\n",
    "        self.node_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Graph convolutional layers\n",
    "        self.conv1 = GCNConv(hidden_dim, 128)\n",
    "        self.bn1 = BatchNorm1d(128)\n",
    "        \n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.bn2 = BatchNorm1d(64)\n",
    "        \n",
    "        # Edge classification layer\n",
    "        self.fc = nn.Linear(128 , output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_index_out):\n",
    "        edge_index = edge_index\n",
    "        x = self.node_embedding(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Edge representations\n",
    "        edge_index_to_compare = edge_index_out\n",
    "        edge_rep = torch.cat([x[edge_index_to_compare[0]], x[edge_index_to_compare[1]]], dim=1)\n",
    "\n",
    "        # Edge classification\n",
    "        edge_scores = torch.sigmoid(self.fc(edge_rep))\n",
    "\n",
    "        return edge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "aacde116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Instantiate the model\n",
    "input_dim = 8\n",
    "hidden_dim = 256\n",
    "output_dim = 1  # Binary classification (citing or not citing)\n",
    "model = EdgeClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0  # No change for the first 10 epochs\n",
    "    else:\n",
    "        return 0.1  # Decrease learning rate by a factor of 10 after 10 epochs\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_schedule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a19af73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    #output = []\n",
    "    totalLossPerEpoch = []\n",
    "    for batch_x, batch_edge_index, batch_edge_index_out, batch_y in data_loader:\n",
    "        batch_x = torch.stack(batch_x).to(device)\n",
    "        batch_edge_index = [edge_index.to(device) for edge_index in batch_edge_index]\n",
    "        #print(batch_edge_index[0].shape)\n",
    "        batch_edge_index_out = [edge_index.to(device) for edge_index in batch_edge_index_out]\n",
    "        batch_y = [y.to(device) for y in batch_y]\n",
    "        #print(len(batch_y))\n",
    "        optimizer.zero_grad()\n",
    "        loss_per_batch = []\n",
    "        for i in range(len(batch_edge_index)):\n",
    "            _output = model(batch_x[i], batch_edge_index[i], batch_edge_index_out[i])\n",
    "            #print(len(_output))\n",
    "            #output.append(_output)\n",
    "            loss = criterion(_output.squeeze(), batch_y[i].squeeze())\n",
    "            #print(loss)\n",
    "            loss_per_batch.append(loss)\n",
    "        #print(loss_per_batch)\n",
    "        #loss_per = torch.tensor(loss_per, dtype=torch.float)\n",
    "        total_loss_per_batch = sum(loss_per_batch)/ len(loss_per_batch)\n",
    "        totalLossPerEpoch.append(total_loss_per_batch)\n",
    "        #total_loss = torch.tensor(total_loss, requires_grad=True) \n",
    "        #print(\"total_loss_per_batch: \",total_loss_per_batch)\n",
    "        #total_loss.backward()\n",
    "        total_loss_per_batch.backward()\n",
    "        optimizer.step()\n",
    "    #print(\"totalLossPerEpoch: \",totalLossPerEpoch)\n",
    "    total_loss_per_epoch = sum(totalLossPerEpoch)/len(totalLossPerEpoch)\n",
    "    print(\"total_loss_per_epoch:\",total_loss_per_epoch)\n",
    "    return total_loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0f7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss_per_epoch: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.5009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "total_loss_per_epoch: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "lossPerEpoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    lossPerEpoch.append(train(model, device, data_loader, optimizer, criterion))\n",
    "    # Update the learning rate at the end of each epoch\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "074ec72c-7eed-4c36-9062-2bd959a2f85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossPerEpoch = [tensor.cpu() for tensor in lossPerEpoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f613be7f-0fa7-4b82-9ac6-99243dad4e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossPerEpoch = [tensor.detach().numpy() for tensor in lossPerEpoch]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
